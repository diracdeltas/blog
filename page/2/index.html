<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
	<meta name="generator" content="Hugo 0.86.0" />
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      discrete blogarithm &middot; 
    
  </title>

  
  <link rel="stylesheet" href="https://blog.azuki.vip/css/poole.css">
  <link rel="stylesheet" href="https://blog.azuki.vip/css/syntax.css">
  <link rel="stylesheet" href="https://blog.azuki.vip/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700|PT+Sans:400">

  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://blog.azuki.vip/assets/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="https://blog.azuki.vip/assets/favicon.ico">

  
  <link rel="alternate" type="application/rss+xml" title="RSS" href="https://blog.azuki.vip/atom.xml">
</head>


  <body>

    
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">


<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>
      yan&rsquo;s blog
    </p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item  active " href="https://blog.azuki.vip/">Home</a>
    <a class="sidebar-nav-item " href="https://blog.azuki.vip/post">Posts</a>
    <a class="sidebar-nav-item " href="https://blog.azuki.vip/about/">About</a>
      </nav>

  <div class="sidebar-item">
    <p>&copy; 2021. All rights reserved.</p>
  </div>
</div>


    
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="https://blog.azuki.vip/" title="Home">discrete blogarithm</a>
            <small></small>
          </h3>
        </div>
      </div>

      <div class="container content">





<div class="posts">
  
    <div class="post">
        <h1 class="post-title"><a href="https://blog.azuki.vip/0x19/">25</a></h1>
        <span class="post-date">May 4, 2016</span>
        <p class="p1">
  i turn 25 in an hour. this seems strange and unbelievable. surely 25 years of existence is enough to become acquainted with the monotonicity of time. but instead the seconds pass and disbelief stares back, unmoving.
</p>
<p class="p1">
  a quarter-century is a long time. with sadness, i realize how much of it i have forgotten already.
</p>
<p class="p1">
  imagine that we could live forever. would we still talk about wasting time if time were an unlimited resource? would we still apologize for being late?
</p>
<p class="p1">
  it seems that we should panic less about wasting time as our lifespan grows. paradoxically, every moment in time is unique and unrepeating, so we should be losing our shit over each precious second that passes.
</p>
<p class="p1">
  i used to imagine the movement of time as like a river, flowing by with theÂ blendedÂ grace and strength of water and gravity. now it feels like a tired jogger limping by on a rhythmless gait, wrecked with joint pain and gasping for air. most steps are slogged with exhaustion, but every once in a while a wave of endorphins crashes in and makes the world spin with brightness.
</p>
<p class="p1">
  how unfortunate it is to be alive during the brief window of history when computers are getting faster just as your body is getting slower. i hope iâ€™m lucky enough to become more of a computer soon.
</p>

    </div>
  
    <div class="post">
        <h1 class="post-title"><a href="https://blog.azuki.vip/happy-birthday/">happy birthday</a></h1>
        <span class="post-date">Dec 17, 2015</span>
        <p>Dear Chelsea,</p>
<p>You probably donâ€™t remember me, but we met in September 2009. This was before everyone knew your name and before many people knew mine.</p>
<p>I was at home, helping my friend cut her hair. Out of the corner of my eye, I saw you walkÂ into the living room. You were taking photos of our mural-covered walls, seemingly happy to be in such a bizarre and interesting house of MIT students. Someone introduced you to me.</p>
<p>That evening, or perhaps the evening after, I learned that you were a soldierÂ training for Iraq. You wanted to leave the military someday and get a degree in Computer Science. You werenâ€™t much older than me, but you sounded more anxious and weary than anyone Iâ€™d ever met before. We chatted for a while, and then I had to go finish my homework.</p>
<p>You left Boston soon after that, and you friended me on Facebook. I accepted your friend request, and that was the last time we interacted with each other.</p>
<p>When you were arrested in 2010, I was proud of what youâ€™d done and angry at what happened to you after (I still am, every day). At the same time, the media <a href="http://tech.mit.edu/V130/N30/wikileaks.html" target="_blank">started suspecting</a> (baselessly) that friends of mine had assisted you in whistleblowing.Â For the first time in my life, I felt like I might be underÂ more surveillance than the average 18 year-old.</p>
<p>It was then that I realized that although I hadnâ€™t done anything wrong, I had reason to be distrustful of the government that I lived under. I had nothing to hide, but nonetheless I was now part of a community under suspicion of a serious crime.</p>
<p>I started learningÂ about security and privacy.Â Soon after, I installed PGP and started using it. Years later, IÂ still think ofÂ you every timeÂ I help others encrypt their communications.</p>
<p>So thanks for teaching me how to be paranoid. Thanks for showing me why everyone should care about surveillance, even if they arenâ€™t a whistleblower. Meeting you was an accident that could have happened to anyone. Iâ€™m glad it happened to me.</p>
<p>Happy 28th Birthday.</p>
<p>-Yan</p>
<p>[PS for readers: You can help support Chelsea by donating to her legal defense team. <a href="https://www.chelseamanning.org/press/chelsea-manning-defense-fund">Info here.</a>]</p>

    </div>
  
    <div class="post">
        <h1 class="post-title"><a href="https://blog.azuki.vip/sniffly/">sniffly</a></h1>
        <span class="post-date">Oct 27, 2015</span>
        <p>Every so often, I get sick of basically everything. Walls become suffocating, routine is insufferable, and the city I live in wraps itself against the sky like a cage. So inevitably I duck away and findÂ something to chase (warm faces, the light in autumn, half-formed schemes, etc.), run until Iâ€™mÂ dizzy and lost and canâ€™t remember whose couch Iâ€™m waking up on or why I crashed there. Weeks later, the sky bruises into swollen dusk, some familiar voice yellsÂ for me to come home so I run back into my bed once again, wondering if home is this place more than it is the feeling ofÂ staring at an unfamiliar timetable and noticing your heartbeat quicken.</p>
<p>This kinda happened last month so I tookÂ a 4 week leave (2 paid, 2 unpaid) from my job to read books, work on open source projects, and couchsurf the East Coast.Â I spent a lot of rainy days curled up on a friendâ€™s bed in Somerville, MA poking at my laptop, idle afternoons hiding in a corner of the MIT library poking at my laptop, and long electric evenings walking around New York City lookingÂ for a place to sit and poke at my laptop. A lot of laptop-poking happened while on â€œvacationâ€ because I had promised some people that I would give two talks in October, one at <a href="http://secretcon.com/" target="_blank">SecretCon</a> and one at <a href="http://sandiego.toorcon.net/" target="_blank">ToorCon</a>.</p>
<p>Predictably, I put off the ToorCon talk until 2 weeks ago. Also predictably, I started panicking and not sleeping anymore because I said I would show people a new browser fingerprinting technique which did not exist. Somehow, after a lot of head-banging-against-desk, I came up with one that sort-of worked about a week before the ToorCon and actually finished the code right before ToorCon. I named it <a href="https://github.com/diracdeltas/sniffly" target="_blank">Sniffly</a> because it sniffs browser history, and also because I was coming down with a cold.</p>
<p>Hereâ€™s how Sniffly works:</p>
<ol>
<li>A user visits theÂ Sniffly page.</li>
<li>Their browser attempts to load images from various HSTS domains over HTTP. These domains were harvested from a scrape of HSTS domains in the Alexa Top 1M. It was really fun to write this scraper; I finally had a chance to use Pythonâ€™s Twisted!</li>
<li>Sniffly sets a CSP policy that restricts images to HTTP, so image sources are blocked before they are redirected to HTTPS. This is crucial, because If the browser completes a request to the HTTPS site, then it will receive the HSTS pin, and the attack will no longer work when the user visits Sniffly.</li>
<li>When an image gets blocked by CSP, its <code>onerror</code> handler is called. In this case, the <code>onerrorÂ </code>handler does some fancy tricks to semi-reliably time how long it took for Â the image to be redirected from HTTP to HTTPS. If this time is on the order of a millisecond, it was an HSTS redirect (no network request was made), which means the user has visited the imageâ€™s domain before. If itâ€™s on the order of 100 milliseconds, then a network request probably occurred, meaning that the user hasnâ€™t visited the imageâ€™s domain.</li>
</ol>
<p><a href="https://zyan.scripts.mit.edu/sniffly/" target="_blank">Hereâ€™s a quick demo</a>. It only works in recent Chrome/Firefox versions when HTTPS Everywhere is disabled. The results also turn up a lot of false positives if you are running an adblocker, since ad-blocked domains are indistinguishable from HSTS-blocked domains from a timing perspective. (However, since HTTPS Everywhere domains and ad-blocked domains are mostly the same for every user, they can simply be subtracted out to get more accurate results for users who run these browser extensions.) I didnâ€™t collect analytics on the site, but random testing with several friends showed a ~80% accuracy rate in the demo once browser extensions were accounted for.</p>
<p>For more info, check out the <a href="https://github.com/diracdeltas/sniffly" target="_blank">source code</a>, <a href="https://zyan.scripts.mit.edu/presentations/toorcon2015.pdf" target="_blank">ToorCon slides</a>Â (pdf), and <a href="https://www.youtube.com/watch?v=kk2GkZv6Wjs" target="_blank">talk recording</a>. Someone submitted theÂ demo toÂ <a href="https://news.ycombinator.com/item?id=10455735" target="_blank">Hacker News</a>Â and, to my horror, it was the #1 link for 6+ hours yesterday (!). I feel bewildered that this kind of attention is being granted (<a href="https://zyan.scripts.mit.edu/blog/backdooring-js/" target="_blank">again</a>) to random side projects that I do alone in my spare time, but I guess I should take whatever validation I can get right now. It would be sweet if people looked at my work and paid me to hack on interesting stuff for the public so i never had to work a real job again. Maybe someday itâ€™ll happen; until then Iâ€™ll prolly hold down a day job and take more fake vacations.</p>
<p><strong>Update: As of March 2016, Sniffly (CVE-2016-1617) has been fixed in the major browsers. Thank you Uncle Google for the bug bounty $$.</strong></p>

    </div>
  
    <div class="post">
        <h1 class="post-title"><a href="https://blog.azuki.vip/tbd/">tbd</a></h1>
        <span class="post-date">Oct 26, 2015</span>
        <p>you know things are getting better when you walk away from the hotel where you just gave two presentationsÂ wearing your best pretenseÂ of holding-it-togetherness while inside you felt shakey, hungover, and insane. remember how long you stood there,Â smiling and rationingÂ weak handshakes while pretending you believed that you had a future? promise yourself youâ€™re never doing that again. you walk away from the volatile company of people who made you feel shittyÂ about yourself without trying to and into the car of someone who looks like they could be your new friend. you drive down the street and pack your bags, take off your stupid clothes and pull on a grey tshirt. now youâ€™re driving down Highway 5 towards LA, the hills are honey-colored, the mountains crashing into sunset sky with symphonic grace, your insecurities start to crack like chipped gold paint.Â you pick at your wrecked fingernails and start to feel like you might have the vaguest idea of what to do with yourself tomorrow morning. then your new friend turns on the stereo and says, â€œdo you want to hear a song i wrote? itâ€™s about how my mom was a cunt.â€ you say, sure.</p>

    </div>
  
    <div class="post">
        <h1 class="post-title"><a href="https://blog.azuki.vip/backdooring-js/">backdooring your javascript using minifier bugs</a></h1>
        <span class="post-date">Aug 24, 2015</span>
        <p>In addition to unforgettable life experiences and personal growth, one thing I got out of DEF CON 23 was aÂ copy of <a href="https://www.alchemistowl.org/pocorgtfo/">POC||GTFO 0x08</a> from Travis Goodspeed. The coolest article Iâ€™ve read so far in it is â€œDeniable Backdoors Using Compiler Bugs,â€ in which the authors abused a pre-existing bug in CLANG to create a backdoored version of sudo that allowed any user to gain root access. This is very sneaky, because nobody could prove that their patch to sudo was a backdoor by examining the source code; instead, the privilege escalation backdoor is inserted at compile-time by certain (buggy) versions of CLANG.</p>
<p>That got me thinking about whether you could use the same backdoor technique on javascript. JS runs pretty much everywhere these days (browsers, servers, <a href="http://postscapes.com/javascript-and-the-internet-of-things">arduinos and robots</a>, maybe even cars someday) but itâ€™s an interpreted language, not compiled. However,Â itâ€™s quite common to minify and optimize JS to reduce file size and improve performance. Perhaps that gives us enough room to insert a backdoor by abusing a JSÂ <em>minifier.</em></p>
<h3 id="part-i-finding-a-good-minifier-bug">Part I: Finding a good minifier bug</h3>
<p>Question: Do popular JS minifiers really have bugs that could lead to security problems?</p>
<p>Answer: After about 10 minutes of searching, I found one in <a href="https://github.com/mishoo/UglifyJS2">UglifyJS</a>, a popular minifier used by jQuery to build a script that runs on something like <a href="http://blog.jquery.com/2014/01/13/the-state-of-jquery-2014/">70% of the top websites</a> on the Internet. The <a href="https://github.com/mishoo/UglifyJS2/issues/751">bug itself</a>,Â fixed in the 2.4.24 release, is straightforwardÂ but not totally obvious, so letâ€™s walk through it.</p>
<p>UglifyJS does a bunch of things to try to reduce file size. One of the compression flags that is on-by-default will compress expressions such as:</p>
<pre>!a && !b && !c && !d
</pre>
<p>That expression is 20 characters. Luckily, if we apply <a href="https://en.wikipedia.org/wiki/De_Morgan%27s_laws">De Morganâ€™s Law</a>, weÂ can rewrite it as:</p>
<pre>!(a || b || c || d)
</pre>
<p>which is only 19 characters. Sweet! Except that De Morganâ€™s Law doesnâ€™t necessarily work if any of the subexpressions has a non-Boolean return value. For instance,</p>
<pre>!false && 1
</pre>
<p>will return the number 1. On the other hand,</p>
<pre>!(false || !1)
</pre>
<p>simply returns true.</p>
<p>SoÂ if we can trick the minifier into erroneously applying De Morganâ€™s law, we can make the program behave differently before and after minification! Turns out itâ€™s not too hard to trick UglifyJS 2.4.23 into doing this, since it will always use the rewritten expression if it is shorter than the original. (UglifyJS 2.4.24 patches this by making sure that subexpressions are boolean before attempting to rewrite.)</p>
<h3 id="part-ii-building-a-backdoorin-some-hypothetical-auth-code">Part II: Building a backdoorÂ in some hypothetical auth code</h3>
<p>Cool, weâ€™ve found the minifier bug of our dreams. Now letâ€™s try to abuse it!</p>
<p>Letâ€™s say that you are working for some company, and you want to deliberately create vulnerabilities in their Node.js website. You are tasked with writing some server-side javascript that validates whether user auth tokens are expired. First you make sure that the Node package uses <a href="mailto:uglify-js@2.4.23">uglify-js@2.4.23</a>, which has the bug that we care about.</p>
<p>Next you write the token validation function, inserting a bunch of plausible-looking config and user validation checks to force the minifier to compress the long (not-)boolean expression:</p>
<pre>function isTokenValid(user) {
    var timeLeft =
        !!config && // config object exists
        !!user.token && // user object has a token
        !user.token.invalidated && // token is not explicitly invalidated
        !config.uninitialized && // config is initialized
        !config.ignoreTimestamps && // don't ignore timestamps
        getTimeLeft(user.token.expiry); // &gt; 0 if expiration is in the future

    // The token must not be expired
    return timeLeft &gt; 0;
}

function getTimeLeft(expiry) {
  return expiry - getSystemTime();
}
</pre>
<p>Running <code>uglifyjs -c</code> on the snippet above produces the following:</p>
<pre>function isTokenValid(user){var timeLeft=!(!config||!user.token||user.token.invalidated||config.uninitialized||config.ignoreTimestamps||!getTimeLeft(user.token.expiry));return timeLeft&gt;0}function getTimeLeft(expiry){return expiry-getSystemTime()}</pre>
<p>In the original form,Â ifÂ the config and user checks pass, <code>timeLeft</code> is a negative integer if the token is expired. In the minified form, <code>timeLeft</code> must be a boolean (since â€œ!â€ in JS does type-coercion to booleans). In fact, if the config and user checks pass, the value of <code>timeLeft</code> is always <code>true</code> unless <code>getTimeLeft</code>Â coincidentally happens to be 0.</p>
<p>Voila! Since <code>true &gt; 0</code> in javascript (yay for type coercion!), auth tokens that are past their expiration timeÂ will still be valid forever.</p>
<h3 id="part-iii-backdooring-jquery">Part III: Backdooring jQuery</h3>
<p>Next letâ€™s abuse our favorite minifier bug toÂ write some patches to jQuery itself that could lead to backdoors. Weâ€™ll work with <a href="https://github.com/jquery/jquery/tree/1.11.3">jQuery 1.11.3</a>, which is the current jQuery 1 stable release as of this writing.</p>
<p>jQuery 1.11.3 usesÂ <a href="https://github.com/jquery/jquery/blob/1.11.3/package.json#L39">grunt-contrib-uglify 0.3.2</a> for minification, which in turn depends on <a href="https://github.com/gruntjs/grunt-contrib-uglify/blob/v0.3.2/package.json#L30">uglify-js ~2.4.0</a>. So <a href="mailto:uglify-js@2.4.23">uglify-js@2.4.23</a> satisfies the dependency, and we can manually edit package.json in grunt-contrib-uglify to force it to use this version.</p>
<p>There are only a handful of places in jQuery where the DeMorganâ€™s Law rewrite optimization is triggered. None of these cause bugs, so weâ€™ll have to add some ourselves.</p>
<p><strong>Backdoor Patch #1:</strong></p>
<p>First letâ€™s add a potential backdoor in jQueryâ€™s .html() method. The <a href="https://github.com/diracdeltas/jquery/commit/e50c8ce26736027386aa7a698baeca7740a54a0b">patch</a> looks weird andÂ superfluous, but we canÂ convince anyone that it shouldnâ€™t actually change what the method does. Indeed, pre-minification, the unit tests pass.</p>
<p>After minification with <a href="mailto:uglify-js@2.4.23">uglify-js@2.4.23</a>, jQueryâ€™s .html() method will set the inner HTML to â€œtrueâ€ instead of the provided value, so a bunch of tests fail.</p>
<p><a href="http://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-1.35.48-PM.png"><img class="alignnone size-full wp-image-670" src="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-1.35.48-PM.png" alt="Screen Shot 2015-08-23 at 1.35.48 PM" width="844" height="785" srcset="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-1.35.48-PM.png 844w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-1.35.48-PM-300x279.png 300w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-1.35.48-PM-624x580.png 624w" sizes="(max-width: 844px) 100vw, 844px" /></a></p>
<p>However, the jQuery maintainers are probably using the patched version of uglifyjs. Indeed, tests pass withÂ uglify-js@2.4.24, so this patch might not seem too suspicious.</p>
<p><a href="http://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-1.39.47-PM.png"><img class="alignnone size-full wp-image-671" src="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-1.39.47-PM.png" alt="Screen Shot 2015-08-23 at 1.39.47 PM" width="1057" height="281" srcset="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-1.39.47-PM.png 1057w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-1.39.47-PM-300x80.png 300w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-1.39.47-PM-1024x272.png 1024w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-1.39.47-PM-624x166.png 624w" sizes="(max-width: 1057px) 100vw, 1057px" /></a></p>
<p>Cool. Now letâ€™s run grunt to build jQuery with this patch and write some silly code that triggers the backdoor:</p>
<pre>&lt;html&gt;
    &lt;script src="../dist/jquery.min.js"&gt;&lt;/script&gt;
    &lt;button&gt;click me to see if this site is safe&lt;/button&gt;
    &lt;script&gt;
        $('button').click(function(e) {
            $('#result').html('&lt;b&gt;false!!&lt;/b&gt;');
        });
    &lt;/script&gt;
    &lt;div id='result'&gt;&lt;/div&gt;
&lt;/html&gt;
</pre>
<p>Hereâ€™s the result of clicking that button when we run the pre-minified jQuery build:</p>
<p><a href="http://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-4.44.45-PM.png"><img class="alignnone size-full wp-image-672" src="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-4.44.45-PM.png" alt="Screen Shot 2015-08-23 at 4.44.45 PM" width="511" height="449" srcset="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-4.44.45-PM.png 511w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-4.44.45-PM-300x264.png 300w" sizes="(max-width: 511px) 100vw, 511px" /></a></p>
<p>As expected, the user is warned that the site is not safe. Which is ironic, because it doesnâ€™t use our minifier-triggered backdoor.</p>
<p>Hereâ€™s what happens when we instead use the minified jQuery build:</p>
<p><a href="http://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-4.45.10-PM.png"><img class="alignnone size-full wp-image-673" src="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-4.45.10-PM.png" alt="Screen Shot 2015-08-23 at 4.45.10 PM" width="505" height="465" srcset="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-4.45.10-PM.png 505w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-4.45.10-PM-300x276.png 300w" sizes="(max-width: 505px) 100vw, 505px" /></a></p>
<p>Now users will totally think that this site is safe even when the site authors are trying to warn them otherwise.</p>
<p><strong>Backdoor Patch #2:</strong></p>
<p>The first backdoor might be too easy to detect, since anyone using itÂ will probably notice that a bunch of HTML is being set to the string â€œtrueâ€ instead of the HTML that they want to set. So our <a href="https://github.com/diracdeltas/jquery/commit/a2092d8a85474c90e2e4d306a21a14af55365b58">second backdoor patch</a> is one that only gets triggered in unusual cases.</p>
<p><a href="http://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-7.48.14-PM.png"><img class="alignnone size-full wp-image-675" src="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-7.48.14-PM.png" alt="Screen Shot 2015-08-23 at 7.48.14 PM" width="1020" height="313" srcset="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-7.48.14-PM.png 1020w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-7.48.14-PM-300x92.png 300w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-7.48.14-PM-624x191.png 624w" sizes="(max-width: 1020px) 100vw, 1020px" /></a></p>
<p>Basically, weâ€™ve modified jQuery.event.remove (usedÂ in the .off() method) so that the code path that calls <a href="https://learn.jquery.com/events/event-extensions/">special event removal hooks</a> never gets reached after minification. (Since <code>spliced</code> is always boolean, its length is always undefined, which is not &gt; 0.) This doesnâ€™t necessarily change the behavior of a site unless the developer has defined such a hook.</p>
<p>Say that the site we want to backdoor has the following HTML:</p>
<pre>&lt;html&gt;
    &lt;script src="../dist/jquery.min.js"&gt;&lt;/script&gt;
    &lt;button&gt;click me to see if special event handlers are called!&lt;/button&gt;
    &lt;div&gt;FAIL&lt;/div&gt;
    &lt;script&gt;
        // Add a special event hook for onclick removal
        jQuery.event.special.click.remove = function(handleObj) {
            $('div').text('SUCCESS');
        };
        $('button').click(function myHandler(e) {
            // Trigger the special event hook
            $('button').off('click');
        });
    &lt;/script&gt;
&lt;/html&gt;
</pre>
<p>If we run it with unminified jQuery, the removal hook gets called as expected:</p>
<p><a href="http://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-4.43.10-PM.png"><img class="alignnone size-full wp-image-677" src="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-4.43.10-PM.png" alt="Screen Shot 2015-08-23 at 4.43.10 PM" width="705" height="545" srcset="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-4.43.10-PM.png 705w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-4.43.10-PM-300x232.png 300w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-4.43.10-PM-624x482.png 624w" sizes="(max-width: 705px) 100vw, 705px" /></a></p>
<p>But the removal hook never gets called if we use the minified build:</p>
<p><a href="http://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-4.43.42-PM.png"><img class="alignnone size-full wp-image-678" src="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-4.43.42-PM.png" alt="Screen Shot 2015-08-23 at 4.43.42 PM" width="714" height="544" srcset="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-4.43.42-PM.png 714w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-4.43.42-PM-300x229.png 300w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/08/Screen-Shot-2015-08-23-at-4.43.42-PM-624x475.png 624w" sizes="(max-width: 714px) 100vw, 714px" /></a></p>
<p>Obviously this is bad news if the event removal hook does some security-critical function, like checking if an origin is whitelisted before passing a userâ€™s auth token to it.</p>
<h3 id="conclusion">Conclusion</h3>
<p>The backdoor examples that Iâ€™ve illustrated are pretty contrived, but the fact that they can exist at all should probably worry JS developers. Although JS minifiers are not nearly as complex or important as C++ compilers, they have power over a lot of the code that ends up running on the web.</p>
<p>Itâ€™s good that UglifyJS has addedÂ test cases for <a href="https://github.com/mishoo/UglifyJS2/blob/master/test/compress/issue-751.js">known bugs</a>, but I would still advise anyone who uses a non-formally verified minifier to be wary. Donâ€™t minify/compress server-side code unless you have to, and make sure you run browser tests/scansÂ against code post-minification. [Addendum: Donâ€™t forget that even if you arenâ€™t using a minifier, your CDN might minify files in production for you. For instance, Cloudflareâ€™s collapsifyÂ <a href="https://github.com/cloudflare/collapsify/commit/e59253193282f2047eea1c770be57cb10c3c4a3a">uses uglifyjs</a>.]</p>
<p>Now, back to reading the rest of POC||GTFO.</p>
<p><strong>PS</strong>: If you have thoughts or ideas for future PoC, please leave a comment or find me on Twitter (<a href="https://twitter.com/bcrypt">@bcrypt</a>). The code from this blog post is up on <a href="https://github.com/diracdeltas/jquery">github</a>.</p>
<p>[Update 1: Thanks @joshssharp for posting this to Hacker News. Iâ€™m flattered to have been on the front page allllll night long (cue 70â€™s soul music). Bonus points â€“ the thread taught me <a href="https://news.ycombinator.com/item?id=10108672">something surprising</a> about why it would make sense to minify server-side.]</p>
<p>[Update 2: There is now a <a href="https://lists.debian.org/debian-devel/2015/08/msg00427.html">long thread</a> about minifiers on debian-devel which spawned <a href="https://wiki.debian.org/onlyjob/no-minification">this wiki page</a> and <a href="https://news.ycombinator.com/item?id=10146157">another HN thread</a>. Itâ€™s cool that JS developers are paying attention to this class of potential security vulnerabilities, but I hope that people complaining about minification also consider transpilers and other JS pseudo-compilers. Iâ€™ll talk more about that in a future blog post.]</p>

    </div>
  
    <div class="post">
        <h1 class="post-title"><a href="https://blog.azuki.vip/this-blog-uses-content-security-policy/">this blog uses Content Security Policy</a></h1>
        <span class="post-date">Jul 26, 2015</span>
        <p><em>FYI: this post is an artifact of the Dark Ages when my blog was self-hosted WordPress. Let us not speak of that time.</em></p>
<p>Having recently given some <a href="https://zyan.scripts.mit.edu/presentations/txjs2015.pdf">talks</a> about <a href="http://www.w3.org/TR/CSP/">Content Security Policy</a> (CSP), I decided just now to enable it on my own blog to prevent cross-site scripting.</p>
<p>This lilâ€™ blogÂ is hosted by the <a href="https://scripts.mit.edu/">MIT Student Information Processing Board</a>Â andÂ runs on a fairly-uncustomized WordPress 4.x installation. Although I could have enabled CSP by modifying my .htaccess file, I chose to use HTML <meta> tags instead so that these instructions would work for people who donâ€™t have shell access to their WordPress host. Unfortunately, CSP using <meta> hasnâ€™t landed in Firefox yet (<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=663570">tracking bug</a>) so I should probably do the .htaccess thing anyway.</p>
<p>Itâ€™s pretty easy to turn on CSP in WordPress from the dashboard:</p>
<ol>
<li>Go to &lt;your_blog_path&gt;/wp-admin/theme-editor.php. Note that this isnâ€™t availableÂ for WordPress-hosted blogs (*.wordpress.com).</li>
<li>Click on Header (header.php) in the sidebar to edit the header HTML.</li>
<li>At the start of the HTML <code>&lt;head&gt;</code> element, add a CSP meta tag with your CSP policy. This blog usesÂ <code>&lt;meta http-equiv=&quot;Content-Security-Policy&quot; content=&quot;script-src 'self'&quot;&gt;</code> which disallows all scripts except from its own origin (including inline scripts). As far as I can tell, this blocks a few inline scripts but doesnâ€™t impede any functionality on a vanilla WordPress instance. You might want a more permissive policy if you use fancy widgets and plugins.</li>
<li>[Bonus points] You can also show a friendly message to users who disable javascriptÂ by adding a <code>&lt;noscript&gt;</code> element to your header.<a href="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/Screen-Shot-2015-07-26-at-2.07.14-PM.png"><img class="alignnone wp-image-599 size-full" src="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/Screen-Shot-2015-07-26-at-2.07.14-PM.png" alt="noscript" width="1128" height="381" srcset="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/Screen-Shot-2015-07-26-at-2.07.14-PM.png 1128w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/Screen-Shot-2015-07-26-at-2.07.14-PM-300x101.png 300w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/Screen-Shot-2015-07-26-at-2.07.14-PM-1024x346.png 1024w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/Screen-Shot-2015-07-26-at-2.07.14-PM-624x211.png 624w" sizes="(max-width: 1128px) 100vw, 1128px" /></a></li>
</ol>
<p>A fun fact I discovered during this process is thatÂ embedding a SoundCloud iframe will include tracking scripts from Google Analytics and scorecardresearch.com. Unfortunately CSP on the embedding page (my blog) doesnâ€™t extend to embedded contexts (soundcloud.com iframe), so those scripts will still run unless youâ€™ve disabled JS.</p>
<p><a href="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/Screen-Shot-2015-07-26-at-3.02.59-PM.png"><img class="alignnone size-full wp-image-600" src="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/Screen-Shot-2015-07-26-at-3.02.59-PM.png" alt="scorecard" width="806" height="594" srcset="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/Screen-Shot-2015-07-26-at-3.02.59-PM.png 806w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/Screen-Shot-2015-07-26-at-3.02.59-PM-300x221.png 300w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/Screen-Shot-2015-07-26-at-3.02.59-PM-624x460.png 624w" sizes="(max-width: 806px) 100vw, 806px" /></a></p>
<p>Thatâ€™s all. I might do more posts on WordPress hardening later or evenÂ write a WP plugin (*shudders at the thought of writing PHP*). More tips are welcome too.</p>
<p>UPDATE (8/24/15): CSP is temporarily disabled on this blog because Google Analytics uses an inline script. Iâ€™ll nonce-whitelist it later and turn CSP back on.</p>

    </div>
  
    <div class="post">
        <h1 class="post-title"><a href="https://blog.azuki.vip/lessons-from-the-ad-blocker-trenches/">lessons from the ad blocker trenches</a></h1>
        <span class="post-date">Jul 17, 2015</span>
        <p>Greetings from the beautiful museum district of Berlin, where Iâ€™ve been trapped in a small conference room all week for the quarterly meeting of the W3C Technical Architecture group. So far weâ€™ve produced two documents this week that I think are pretty good:</p>
<ul>
<li><a href="http://www.w3.org/2001/tag/doc/encryption-finding/">no encryption backdoors</a></li>
<li><a href="http://www.w3.org/2001/tag/doc/unsanctioned-tracking/">no non-consensual web tracking</a></li>
</ul>
<p>I just realized I have a few more things to say about the latter, based on my experience building and maintaining a semi-popular ad blocker (<a href="https://eff.org/privacybadger" target="_blank">Privacy Badger Firefox</a>).</p>
<ol>
<li>Beware of ad blockers that donâ€™t actually block requests to tracking domains. For instance, an ad blocker that simply hides ads using CSS rules is not really useful for preventing tracking. Many users canâ€™t tell the difference.</li>
<li>Third-party cookies are not the only way to track users anymore, which means that browser features and extensions that only block/delete third-party cookies are not as useful as they once were. This 2012 survey paper [<a href="https://jonathanmayer.org/papers_data/trackingsurvey12.pdf" target="_blank">PDF</a>] by Jonathan Mayer et. al. has a table of non-cookie browser tracking methods, which is probably out of date by now: <a href="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/Screen-Shot-2015-07-17-at-4.32.55-PM.png"><img class="alignnone size-full wp-image-577" src="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/Screen-Shot-2015-07-17-at-4.32.55-PM.png" alt="Screen Shot 2015-07-17 at 4.32.55 PM" width="421" height="684" srcset="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/Screen-Shot-2015-07-17-at-4.32.55-PM.png 421w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/Screen-Shot-2015-07-17-at-4.32.55-PM-185x300.png 185w" sizes="(max-width: 421px) 100vw, 421px" /></a></li>
<li>Detecting whether a domain is performing third-party tracking is not straightforward. Naively, you could do this by counting the number of first-party domains that a domain reads high-entropy cookies from in a third-party context. However, this doesnâ€™t encompass reading non-cookie browser state that could be used to uniquely identify users in aggregate (see table above). A more general but probably impractical approach is to try to tag every piece of site-readable browser state with an entropy estimate so that you can score sites by the total entropy that is readable by them in a third-party context. (We assume that while a site is being accessed as a first-party, the user implicitly consents to letting it read information about them. This is a gross simplification, since first parties can read lots of information that users donâ€™t consent to by invisible fingerprinting. Also, I am recklessly using the term â€œentropyâ€ here in a way that would probably cause undergrad thermodynamics professors to have aneurysms.)</li>
<li>The browser definition of â€œthird-partyâ€ only roughly approximates the real-life definition. For instance, dropbox.com andÂ dropboxusercontent.com are the same party from a business and privacy perspective but not from the cookie-scoping or DNS or same-origin-policy perspective.</li>
<li>The hardest-to-block tracking domains are the ones who cause collateral damage when blocked. A good example of this is Disqus, commonly embedded as a third-party widget on blogs and forums; if we block requests to Disqus (which include cookies for logged-in users), we severely impede the functionality of many websites. So Disqus is too usability-expensive to block, even though they can track your behavior from site to site.</li>
<li>The hardest-to-block tracking methods are the ones that cause collateral damage when disabled. For instance, <a href="http://www.radicalresearch.co.uk/lab/hstssupercookies">HSTS</a> and <a href="https://tools.ietf.org/html/rfc7469#section-5">HPKP</a> both store user-specific persistent data that can be abused to probe usersâ€™ browsing histories and/or mark users so that you can re-identify them after the first time they visit your site. However, clearing HSTS/HPKP state between browser sessions dilutes their security value, so browsers/extensions are reluctant to do so.</li>
<li>Specifiers and implementers sometimes argue that Feature X, which adds some fingerprinting/tracking surface, is okay because itâ€™s no worse than cookies. I am skeptical of this argument for the following reasons:<br clear="none" />a. Unless explicitly required, there is no guarantee that browsers will treat Feature X the same as cookies in privacy-paranoid edge cases. For instance, if Safari blocks 3rd party cookies by default, will it block 3rd party media stream captures (which will store a unique deviceid) by default too?<br clear="none" />b. Ad blockers and anti-tracking tools like Disconnect, Privacy Badger, and Torbutton were mostly written to block and detect tracking on the basis of cookies, not arbitrary persistent data. Itâ€™s arguable that they should be blocking these other things as soon as they are shipped in browsers, but that requires developer time.</li>
</ol>
<p>Thatâ€™s all. And hereâ€™s some photos I took while walking around Berlin in a jetlagged haze for hours last night:</p>
<p><a href="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/berlin1.jpg"><img class="alignnone  wp-image-586" src="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/berlin1.jpg" alt="berlin1" width="391" height="391" srcset="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/berlin1.jpg 1080w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/berlin1-150x150.jpg 150w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/berlin1-300x300.jpg 300w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/berlin1-1024x1024.jpg 1024w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/berlin1-624x624.jpg 624w" sizes="(max-width: 391px) 100vw, 391px" /></a></p>
<p><a href="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/berlin2.jpg"><img class="alignnone  wp-image-587" src="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/berlin2.jpg" alt="berlin2" width="392" height="392" srcset="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/berlin2.jpg 1080w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/berlin2-150x150.jpg 150w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/berlin2-300x300.jpg 300w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/berlin2-1024x1024.jpg 1024w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/07/berlin2-624x624.jpg 624w" sizes="(max-width: 392px) 100vw, 392px" /></a></p>
<p>Update (7/18/15): Artur Janc of Google pointed out this <a href="https://www.chromium.org/Home/chromium-security/client-identification-mechanisms" target="_blank">document by folks at Chromium</a> analyzing various client identification methods, including several I hadnâ€™t thought about.</p>

    </div>
  
    <div class="post">
        <h1 class="post-title"><a href="https://blog.azuki.vip/pseudorandom-podcast-series-episode-1/">pseudorandom podcast series, episode 1</a></h1>
        <span class="post-date">Jun 7, 2015</span>
        <p>The combination of my roommate starting a Rust podcast and a long, animated conversation with a (drunk) storyteller last night caused me to become suddenly enamored with the idea of starting my own lilâ€™ podcast. Lately I keep thinking about how many spontaneous, insightful conversations are never remembered, much less entombed in a publicly-accessible server for posterity. So a podcast seemed like an excellent way to share these moments without spending a lot of time writing (Iâ€™m a regrettably slow writer).Â Iâ€™dÂ simplyÂ bring folks into my warehouse living room, give them a beverage of their choice, and spend a leisurely hour chatting about whatever miscellaneous topics came to mind.</p>
<p>And so, wasting no time, today I asked my ex-ex-colleague Peter Eckersley if he would like to be my first podcast guest. Peter runs the technology projects team at the Electronic Frontier Foundation and, more importantly, lives 3 blocks away from me. Fortuitously,Â Peter agreed to have me over for a chat later this afternoon.</p>
<p>When I arrived, it turned out that one of Peterâ€™s housemates was having friends over for dinner, so finding a quiet spot became a challenge. We ended up in a tiny room at the back of his house where every flat surface was covered in sewing equipment and sundry household items. As Peter grabbed a hammer to reconstruct the only available chair in the room, I set up my laptop and fancy (borrowed) podcast microphone. We gathered around as close as we could andÂ hit the record button.</p>
<p>Except forÂ one hiccup where Audacity decided to stop recording abruptly, the interview went smoothly and didnâ€™t need much editing. Next time Iâ€™ll plan to put myself closer to the mic, do a longer intro, and maybe cut the length down to 15 minutes.</p>
<p><a href="https://soundcloud.com/bcrypt/pseudorandom-podcast-episode-1" target="_blank">Here is the result</a>.</p>
<p>Overall, I had a fun time recording this podcast and am unduly excited about future episodes. Turns out a podcast takes ~10% of the time to write a blog post with the same content. ğŸ™‚</p>
<p>For this and future episodes in the Pseudorandom Podcast Series, hereâ€™s an <a href="http://feeds.soundcloud.com/users/soundcloud:users:156877463/sounds.rss" target="_blank">RSS feed</a>. Iâ€™m going to reach SoundCloudâ€™s limit of 180 minutes real quick at this rate, so I will probably host these somewhere else in the future or start a microfunding campaign to pay $15/month.</p>

    </div>
  
    <div class="post">
        <h1 class="post-title"><a href="https://blog.azuki.vip/life-update/">life update</a></h1>
        <span class="post-date">Apr 27, 2015</span>
        <p>iâ€™ve finally recovered enough from a multi-week bout of sickness to say some things and put up some photos. lately iâ€™ve felt exhausted and lethargic and unproductive to be honest. being sick probably had something to do with it; i sure hope next week gets better.</p>
<p>yesterday, someone told me they had a theory that everyone who sleeps at night (with rare exceptions) can only manage ~3 significant life events at a time. that sounds about right, but it feels like a lot has been going on. a partial, unordered list:</p>
<ol>
<li>talked yesterday at the Yahoo Trust Unconference about <a href="https://zyan.scripts.mit.edu/presentations/trust_unconference.html">the future of email security</a></li>
</ol>
<div id="attachment_558" style="width: 423px" class="wp-caption alignnone">
  <a href="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/04/yan_sec.jpg"><img class="wp-image-558" src="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/04/yan_sec.jpg" alt="yan" width="413" height="413" srcset="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/04/yan_sec.jpg 640w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/04/yan_sec-150x150.jpg 150w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/04/yan_sec-300x300.jpg 300w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/04/yan_sec-624x624.jpg 624w" sizes="(max-width: 413px) 100vw, 413px" /></a>
  <p class="wp-caption-text">
    photo credit Bill Childers
  </p>
</div>
<ol start="2">
<li>
<p>working on graceful degradation of hopes and feelings</p>
</li>
<li>
<p>writing software for Letâ€™s Encrypt as an EFF Technology fellow</p>
</li>
<li>
<p>trying to make sane w3c standards with these fine folks from the W3C Technical Architecture group</p>
</li>
</ol>
<div id="attachment_557" style="width: 426px" class="wp-caption alignnone">
  <a href="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/04/TAG.jpg"><img class="wp-image-557" src="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/04/TAG.jpg" alt="TAG" width="416" height="416" srcset="https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/04/TAG.jpg 640w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/04/TAG-150x150.jpg 150w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/04/TAG-300x300.jpg 300w, https://zyan.scripts.mit.edu/blog/wp-content/uploads/2015/04/TAG-624x624.jpg 624w" sizes="(max-width: 416px) 100vw, 416px" /></a>
  <p class="wp-caption-text">
    photo credit Tantek Celik
  </p>
</div>
<ol start="5">
<li>
<p>packing bag(s) and moving to a new neighborhood (twice)</p>
</li>
<li>
<p>finding balance on a skateboard and otherwise</p>
</li>
</ol>
<p>â€œI think emotional and crypto intelligence are severely underratedâ€ â€“ spectator at the Yahoo Trust Unconference.</p>

    </div>
  
    <div class="post">
        <h1 class="post-title"><a href="https://blog.azuki.vip/rate-limiting-anonymous-accounts/">rate-limiting anonymous accounts</a></h1>
        <span class="post-date">Mar 5, 2015</span>
        <p>Yesterday TechCrunch <a href="http://techcrunch.com/2015/03/02/twitter-tor-phone-verification/">reported</a> that Twitter now seems to be requiring SMS validation from new accounts registered over Tor. Though this might be effective for rate-limiting registration of abusive/spammy accounts, sometimes <a href="http://www.washingtonpost.com/blogs/the-switch/wp/2014/03/24/tor-usage-in-turkey-surges-during-twitter-ban/">actual people</a> use Twitter over Tor because anonymity is a prerequisite to free speech and circumventing information barriers imposed by oppressive governments. These users might not want to link their telco-sanctioned identity with their Twitter account, hence why theyâ€™re using Tor in the first place.</p>
<p>What are services like Twitter to do, then? I thought of one simple solution that borrows a popular idea from anonymous e-cash systems.</p>
<p>In a <a href="http://www.hit.bme.hu/~buttyan/courses/BMEVIHIM219/2009/Chaum.BlindSigForPayment.1982.PDF">1983 paper</a>, cryptographer David Chaum introduced the concept of blind signatures. A blind signature is a cryptographic signature in which the signer canâ€™t see the content of the message that sheâ€™s signing. So if Bob wants Alice to sign the message â€œBob is greatâ€ without her knowing, he first â€œblindsâ€ the message using a random factor that is unknown to her and gives Alice the blinded message to sign. When he unblinds her signed message by removing the blinding factor, the original message â€œBob is greatâ€ <em>also</em> has a valid signature from Alice!</p>
<p>This may seem weird and magical, but blinded signatures are actually possible using the familiar RSA signature scheme. The proof is straightforward and <a href="https://en.wikipedia.org/wiki/Blind_signature#Blind_RSA_signatures.5B2.5D:235">on Wikipedia</a>. Basically, since RSA signatures are just moduloâ€™d exponentiation of some message <em>M</em> to a secret exponent <em>d</em>, when you create a signature over a blinded message <em>Mâ€™ = M*r^e</em> (where <em>r</em> is the blinding factor and <em>e</em> is the public exponent), you also create a valid signature over <em>M</em> thanks to the distributive property of exponentiation over multiplication.</p>
<p>Given the existence of blind signature schemes, Twitter can do something like the following to rate-limit Tor accounts without deanonymizing them:</p>
<ol>
<li>Say that @bob is an existing Twitter user who would like to make an anonymous account over Tor, which weâ€™ll call @notbob. He computes <em>T = H(notbob) * r^e mod N</em>, where <em>H</em> is a hash function, <em>r</em> is a random number that Bob chooses, and <em>{e,N}</em> is the public part of an Identity Providerâ€™s RSA keypair (defined in step 2).</li>
<li>Bob sends <em>T</em> to anÂ identity provider. This could be Twitter itself, or any service like Google, Identica, Facebook, LinkedIn, Keybase, etc. as long as it can check that Bob is probably a real person via SMS verification or a reputation-based algorithm. If Bob seems real enough, the Identity Provider sends him S_ig(T) = T^d mod N = H(notbob)^d * r mod N_, where _d_ is the private part of the Identity Providerâ€™s RSA keypair.</li>
<li>Bob divides <em>Sig(T)</em> by <em>r</em> to get <em>Sig(H(notbob))</em>, AKA his Identity Providerâ€™s signature over the hash of his desired anonymous username.</li>
<li>Bob opens up Tor browser and goes to register @notbob. In the registration form, he sends <em>Sig(H(notbob))</em>. Twitter can then verify the Identity Providerâ€™s signature over â€˜notbobâ€™ and <strong>only</strong> accept @notbobâ€™s account registration if verification is successful!</li>
</ol>
<p>It seems to me that this achieves some nice properties.</p>
<ul>
<li>Every anonymous account is transitively validated via SMS or reputation.</li>
<li>Ignoring traffic analysis (admittedly a big thing to ignore), anonymous accounts and the actual identities or phone numbers used to validate them are unlinkable.</li>
</ul>
<p>Thoughts? Iâ€™d bet that someone has thought of this use case before but I couldnâ€™t find any references on the Internet.</p>

    </div>
  
</div>

<div class="pagination">
  
  <a class="pagination-item older" href="https://blog.azuki.vip/page/3/">Older</a>
  

  
  <a class="pagination-item newer" href="https://blog.azuki.vip/">Newer</a>
  
</div>

      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>
    
  </body>
</html>

