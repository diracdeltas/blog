<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cryptography on discrete blogarithm</title>
    <link>https://diracdeltas.github.io/blog/tags/cryptography/</link>
    <description>Recent content in Cryptography on discrete blogarithm</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Fri, 13 Sep 2013 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://diracdeltas.github.io/blog/tags/cryptography/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Some thoughts on the NSA and elliptic curve cryptography</title>
      <link>https://diracdeltas.github.io/blog/some-thoughts-on-the-nsa-and-elliptic-curve-cryptography/</link>
      <pubDate>Fri, 13 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>https://diracdeltas.github.io/blog/some-thoughts-on-the-nsa-and-elliptic-curve-cryptography/</guid>
      <description>&lt;p&gt;Below is an amalgamation of some posts that I made recently on a popular microblogging platform:&lt;/p&gt;

&lt;p&gt;========&lt;/p&gt;

&lt;p&gt;&lt;span class=&#34;userContent&#34;&gt;I&amp;#8217;ve been reading a lot today about what I believe is a super-likely NSA backdoor into modern cryptosystems.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;There are these things called elliptic curves that are getting used more and more for key generation in cryptography, especially &lt;span class=&#34;text_exposed_show&#34;&gt;in forward-secrecy-enabled SSL (which is the EFF-recommended way to secure web traffic). The problem is that the choice of parameters for the elliptic curves most used in practice are set by NIST, and we know for sure that the NSA has some influence on NIST standards.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;In 2006, NIST published an algorithm for elliptic-curve based random number generation that was shown to be easily breakable but ONLY by whoever chose the elliptic curve parameters. Luckily this algorithm was crazy slow so nobody used it, even though it was the (only?) NIST-recommended way of generating random bits with elliptic curves.&lt;/p&gt;

&lt;p&gt;But it turns out there are some &lt;a href=&#34;https://eprint.iacr.org/2003/058.pdf&#34;&gt;relatively-obscure papers&lt;/a&gt; that suggest that you can gain a decent cryptographic advantage by picking the elliptic curve parameters! [Edit: It was later &lt;a href=&#34;http://www.scottaaronson.com/blog/?p=1517#comment-87087&#34;&gt;pointed out&lt;/a&gt; to me that this particular attack is not close to anything &lt;span class=&#34;userContent&#34;&gt;&lt;span class=&#34;text_exposed_show&#34;&gt;the NSA could be doing right now, for various reasons. It is of course unclear whether they have knowledge of other elliptic curve parameter-based attacks that are not in the academic literature.]&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;This is terrifying, because the elliptic curve parameters chosen for relatively-mysterious reasons by NIST (probably via NSA) are used by Google, OpenSSL, and any RFC-compliant implementation of elliptic curves in OpenPGP (gnupg-ecc, for instance).&lt;/p&gt;

&lt;p&gt;&lt;span class=&#34;userContent&#34;&gt;&lt;span class=&#34;text_exposed_show&#34;&gt;==========&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class=&#34;userContent&#34;&gt;Some people might be wondering if they can trust companies who issue statements that their closed-source software products don&amp;#8217;t contain NSA backdoors (Microsoft, Google, Apple, etc.). Here is an example of why not.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;It has been known since &lt;span class=&#34;text_exposed_show&#34;&gt;2006 that Dual EC DRBG (a NIST-standardized random bit generation algorithm) has a major vulnerability that makes no sense except as an NSA backdoor. Essentially, the algorithm contains some constant parameters that are left unexplained; some researchers then showed that whoever determined these parameters could easily predict the output of the algorithm if they had access to a special set of secret numbers (analogous to an RSA private key). This is a beautiful design for a crytographic backdoor, because the secret numbers are difficult to find except by the person who set the constant parameters in the algorithm.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Despite being slower than other random bit generators, Dual EC DRBG is implemented in a bunch of software products by major companies like RSA Security, Microsoft, Cisco, BlackBerry, McAfee, Certicom, and Samsung. For a full list, see: &lt;a href=&#34;http://csrc.nist.gov/groups/STM/cavp/documents/drbg/drbgval.html&#34; target=&#34;_blank&#34; rel=&#34;nofollow nofollow&#34;&gt;&lt;a href=&#34;http://csrc.nist.gov/groups/STM/cavp/documents/drbg/drbgval.html&#34;&gt;http://csrc.nist.gov/groups/STM/cavp/documents/drbg/drbgval.html&lt;/a&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Most of these products are closed-source, so you can&amp;#8217;t check whether your encryption keys are being generated with Dual EC DRBG.&lt;/p&gt;

&lt;p&gt;This is a pretty strong argument that secure software is necessarily open source software.&lt;/p&gt;

&lt;p&gt;&lt;span class=&#34;userContent&#34;&gt;&lt;span class=&#34;text_exposed_show&#34;&gt;========&lt;br /&gt; &lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class=&#34;userContent&#34;&gt;&lt;span class=&#34;text_exposed_show&#34;&gt;Additional citations:&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-ft=&#34;{&amp;quot;tn&amp;quot;:&amp;quot;K&amp;quot;}&#34; data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2]&#34;&gt;&lt;span data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0]&#34;&gt;&lt;span data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0].[3]&#34;&gt;Bruce Schneier on the 2006 backdoor discovery in Dual_EC_DRBG: &lt;/span&gt;&lt;a href=&#34;https://www.schneier.com/blog/archives/2007/11/the_strange_sto.html&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0].[4]&#34;&gt;&lt;a href=&#34;https://www.schneier.com/&amp;amp;#8230;/2007/11/the_strange_sto.html&#34;&gt;https://www.schneier.com/&amp;amp;#8230;/2007/11/the_strange_sto.html&lt;/a&gt;&lt;/a&gt;&lt;br data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0].[6]&#34; /&gt;&lt;br data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0].[7]&#34; /&gt;&lt;span data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0].[8]&#34;&gt;Google&amp;#8217;s blog post announcing SSL w/ forward secrecy, specifically mentioning that they use the P-256 curve: &lt;/span&gt;&lt;a href=&#34;https://www.imperialviolet.org/2011/11/22/forwardsecret.html&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0].[9]&#34;&gt;&lt;a href=&#34;https://www.imperialviolet.org/2011/11/22/forwardsecret.html&#34;&gt;https://www.imperialviolet.org/2011/11/22/forwardsecret.html&lt;/a&gt;&lt;/a&gt;&lt;br data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0].[10]&#34; /&gt;&lt;br data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0].[11]&#34; /&gt;&lt;span data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0].[12]&#34;&gt;Wiki section on NIST-recommended curves: &lt;/span&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Elliptic_curve_cryptography#NIST-recommended_elliptic_curves&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0].[13]&#34;&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Elliptic_curve_cryptography&amp;amp;#8230&#34;&gt;https://en.wikipedia.org/wiki/Elliptic_curve_cryptography&amp;amp;#8230&lt;/a&gt;;&lt;/a&gt;&lt;br data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0].[14]&#34; /&gt;&lt;br data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0].[15]&#34; /&gt;&lt;span data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0].[16]&#34;&gt;RFC section stating that P-256 is REQUIRED for ecc in openpgp: &lt;/span&gt;&lt;a href=&#34;http://tools.ietf.org/html/rfc6637#section-12.1&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0].[17]&#34;&gt;&lt;a href=&#34;http://tools.ietf.org/html/rfc6637#section-12.1&#34;&gt;http://tools.ietf.org/html/rfc6637#section-12.1&lt;/a&gt;&lt;/a&gt;&lt;br data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0].[18]&#34; /&gt;&lt;br data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0].[19]&#34; /&gt;&lt;span data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0].[20]&#34;&gt;Description of elliptic curve usage in OpenSSL: &lt;/span&gt;&lt;a href=&#34;http://wiki.openssl.org/index.php/Elliptic_Curve_Cryptography&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0].[21]&#34;&gt;&lt;a href=&#34;http://wiki.openssl.org/&amp;amp;#8230;/Elliptic_Curve_Cryptography&#34;&gt;http://wiki.openssl.org/&amp;amp;#8230;/Elliptic_Curve_Cryptography&lt;/a&gt;&lt;/a&gt;&lt;br data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0].[22]&#34; /&gt;&lt;br data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0].[23]&#34; /&gt;&lt;span data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0].[24]&#34;&gt;Presentation on security dangers of NIST curves: &lt;/span&gt;&lt;a href=&#34;http://cr.yp.to/talks/2013.05.31/slides-dan+tanja-20130531-4x3.pdf&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0].[25]&#34;&gt;&lt;a href=&#34;http://cr.yp.to/&amp;amp;#8230;/slides-dan+tanja-20130531-4&amp;amp;#215;3.pdf&#34;&gt;http://cr.yp.to/&amp;amp;#8230;/slides-dan+tanja-20130531-4&amp;amp;#215;3.pdf&lt;/a&gt;&lt;/a&gt;&lt;br data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0].[26]&#34; /&gt;&lt;br data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0].[27]&#34; /&gt;&lt;span data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0].[28]&#34;&gt;NSA page recommending you use elliptic curves lol: &lt;/span&gt;&lt;a href=&#34;http://www.nsa.gov/business/programs/elliptic_curve.shtml&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0].[29]&#34;&gt;&lt;a href=&#34;http://www.nsa.gov/business/programs/elliptic_curve.shtml&#34;&gt;http://www.nsa.gov/business/programs/elliptic_curve.shtml&lt;/a&gt;&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-ft=&#34;{&amp;quot;tn&amp;quot;:&amp;quot;K&amp;quot;}&#34; data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2]&#34;&gt;&lt;span data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0]&#34;&gt;&lt;a href=&#34;http://www.nsa.gov/business/programs/elliptic_curve.shtml&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34; data-reactid=&#34;.r[3ztcq].[1][4][1]{comment10200823098442317_5008296}.[0].{right}.[0].{left}.[0].[0].[0][2].[0].[29]&#34;&gt;Â &lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;userContent&#34;&gt;&lt;span class=&#34;text_exposed_show&#34;&gt;========&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class=&#34;userContent&#34;&gt;&lt;span class=&#34;text_exposed_show&#34;&gt;UPDATE (9/23/13): RSA security has issued an advisory to stop using some of their products where DUAL_EC_DRBG is the default random number generator (&lt;a href=&#34;http://arstechnica.com/security/2013/09/stop-using-nsa-influence-code-in-our-product-rsa-tells-customers/&#34;&gt;http://arstechnica.com/security/2013/09/stop-using-nsa-influence-code-in-our-product-rsa-tells-customers/&lt;/a&gt;). Matthew Green also made an excellent blog post about this topic over at &lt;a href=&#34;http://blog.cryptographyengineering.com/2013/09/the-many-flaws-of-dualecdrbg.html&#34;&gt;http://blog.cryptographyengineering.com/2013/09/the-many-flaws-of-dualecdrbg.html&lt;/a&gt;.&lt;br /&gt; &lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Some thoughts on Facebook implementing forward secrecy</title>
      <link>https://diracdeltas.github.io/blog/some-thoughts-on-facebook-implementing-forward-secrecy/</link>
      <pubDate>Thu, 04 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>https://diracdeltas.github.io/blog/some-thoughts-on-facebook-implementing-forward-secrecy/</guid>
      <description>&lt;p&gt;Last month, &lt;a href=&#34;http://news.cnet.com/8301-13578_3-57591179-38/data-meet-spies-the-unfinished-state-of-web-crypto/&#34;&gt;CNET announced&lt;/a&gt; that Facebook is working on implementing a property called &lt;strong&gt;forward secrecy&lt;/strong&gt; in its encryption of user data. The article is pretty long, but the gist of it is:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Perfect_forward_secrecy&#34;&gt;Forward secrecy&lt;/a&gt; is good news, at least theoretically. Right now, when you send data to Facebook&amp;#8217;s servers, your data gets encrypted so that someone who intercepts your data can&amp;#8217;t read it unless they have Facebook&amp;#8217;s secret key. However, if an eavesdropper is recording your messages now and somehow gets the secret key in the future, they can go back and decrypt all your encrypted communications. Forward secrecy in an encryption protocol, by definition, means that &lt;strong&gt;if the secret key is compromised, your communications are still safe from decryption&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Google is the only major web service that has forward secrecy in its encryption protocol enabled by default. Most services don&amp;#8217;t do this because it&amp;#8217;s computationally expensive.&lt;/li&gt;
&lt;li&gt;The &lt;a href=&#34;http://www.guardian.co.uk/world/2013/jun/08/nsa-prism-server-collection-facebook-google&#34;&gt;leaked slides&lt;/a&gt; about the NSA surveillance program, PRISM, suggest that the NSA is tapping into Internet connections and collecting data in transit between your computer and Facebook&amp;#8217;s servers, or at least that this is possible.&lt;/li&gt;
&lt;li&gt;Once your data is collected by the NSA, it can probably just sit around forever. That gives plenty of time for Facebook&amp;#8217;s secret keys to be brute-forced or obtained by the NSA through a court order. Without perfect secrecy, all your data can be decrypted once this happens.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So in other words, Facebook is implementing an extra security measure to protect &lt;strong&gt;data in transit&lt;/strong&gt; from users to their servers, and this announcement comes at an opportune time in light of the &lt;a href=&#34;https://en.wikipedia.org/wiki/Perfect_forward_secrecy&#34;&gt;PRISM&lt;/a&gt; revelations in early July.&lt;/p&gt;

&lt;p&gt;But data in transit isn&amp;#8217;t the only kind of data that needs to be protected! What about &lt;strong&gt;data at rest&lt;/strong&gt;?&lt;/p&gt;

&lt;p&gt;To clarify what I mean here, let&amp;#8217;s think about the flow of data from you to your friends when you make a FB post. This is simplified, but it goes something like:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;You type a message in a text box in your web browser and hit send.&lt;/li&gt;
&lt;li&gt;Your browser encrypts that message before it leaves your computer and goes on its way to a Facebook server.&lt;/li&gt;
&lt;li&gt;Your message travels over the Internet in encrypted form.&lt;/li&gt;
&lt;li&gt;Your message reaches a Facebook server, which decrypts the message and stores it in a database so that it can be retrieved later to be shown on your profile, in your friends&amp;#8217; news feeds, in searches, and so forth.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In Steps 3 and 4, your data goes from in transit to at rest. Here&amp;#8217;s a handy diagram from &lt;a href=&#34;https://en.wikipedia.org/wiki/File:3_states_of_data.jpg&#34;&gt;Wikipedia&lt;/a&gt; that distinguishes the three states of data, which I&amp;#8217;m simplifying into two by merging &amp;#8220;data at rest&amp;#8221; and &amp;#8220;data in use&amp;#8221;:&lt;/p&gt;

&lt;div style=&#34;width: 576px&#34; class=&#34;wp-caption alignnone&#34;&gt;
  &lt;img alt=&#34;&#34; src=&#34;https://upload.wikimedia.org/wikipedia/commons/2/23/3_states_of_data.jpg&#34; width=&#34;566&#34; height=&#34;343&#34; /&gt;
  
  &lt;p class=&#34;wp-caption-text&#34;&gt;
    Three states of data.
  &lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Nowadays, it&amp;#8217;s expected for major web services to encrypt all data in transit by default using &lt;a href=&#34;https://en.wikipedia.org/wiki/HTTP_Secure&#34;&gt;HTTPS&lt;/a&gt;, which uses the &lt;strong&gt;SSL/TLS&lt;/strong&gt; cryptographic protocols. This is generally done by using a persistent private server key for both &lt;strong&gt;authentication&lt;/strong&gt; (verifying the server&amp;#8217;s identity) and &lt;strong&gt;encryption&lt;/strong&gt; (encoding the data so that only the server can read it). This does not provide forward secrecy, and all encrypted messages are compromised once the persistent server key is found.&lt;/p&gt;

&lt;p&gt;Facebook&amp;#8217;s announcement, which follows one by Google in 2011, reflects a recent shift toward supporting forward secrecy by generating ephemeral Diffie Hellman keys for encryption during each session. A persistent RSA key is still used to authenticate the server. The ephemeral keys used for encryption, however, are &lt;strong&gt;not stored beyond a session&lt;/strong&gt;. Thus, even if the persistent key is compromised, data that has been obtained through eavesdropping on an Internet connection is still safe from decryption.&lt;/p&gt;

&lt;p&gt;However, recall that in Step 4 above, Facebook decrypts your data and stores it in a database, presumably one that is password-protected or has some other security measure that lets a trusted set of people access it (database admins, for instance). At this point, your data is just sitting around in decrypted form, protected by whatever-FB-does-to-protect-its-servers. It would be impractical to do otherwise because performing encrypted query operations efficiently is &lt;a href=&#34;https://en.wikipedia.org/wiki/Homomorphic_encryption&#34; target=&#34;_blank&#34;&gt;hard maths&lt;/a&gt;, and basically the definition of a web app is something that stores data and performs interesting/useful queries.&lt;/p&gt;

&lt;p&gt;With Facebook&amp;#8217;s announcement of support for forward secrecy in TLS/SSL, we&amp;#8217;ve been assured of increased attention to security for data in transit, but this of course says nothing about data at rest. Indeed, it seems that the NSA surveillance leaks have sparked relatively little discussion of policies at companies like Facebook for securing data at rest. That&amp;#8217;s surprising to me, because the oft-spoken phrase &amp;#8220;NSA back door&amp;#8221; vividly suggests that the NSA is in the trusted set of people who have access to the decrypted data in servers at FB, Google, and so forth.&lt;/p&gt;

&lt;p&gt;To be clear, forward secrecy is effective against a particular adversary model, namely wiretapping. Although the CNET article points out that the NSA is probably doing a bunch of wiretapping these days and has agreements with Internet service providers to facilitate such, I assume it&amp;#8217;s still easy for the NSA to walk up to someone at Facebook and demand access to the database. In fact, regardless of how secure data is while in transit, it basically always needs to get decrypted on the server side in order to be useful for a web service. As long as it&amp;#8217;s easy for the web service to access the decrypted data, it&amp;#8217;s easy for the NSA to do so as well*.&lt;/p&gt;

&lt;p&gt;*Barring policy changes that would legally prevent surveillance. Even so &amp;hellip;&lt;/p&gt;

&lt;p&gt;In short, there probably exists no NSA-proof cryptographic protocol for securing data at rest so long as companies agree to comply with gov-authorized surveillance programs. Forward secrecy doesn&amp;#8217;t seem like much of a deterrent to PRISM in that case.&lt;/p&gt;

&lt;p&gt;But in terms of protecting our privacy from attackers who &lt;strong&gt;aren&amp;#8217;t&lt;/strong&gt; government spying agencies, the security of data at rest matters as much as, if not more than, security for data in transit. Unfortunately, whereas TLS/SSL is an established and widely-used standard for encrypting data in transit (albeit flawed in practice), procedures for securing data at rest seem to vary widely between companies (see Appendix A). These procedures are often described in vague terms if at all. For instance, &lt;a href=&#34;https://www.cloze.com/&#34;&gt;one service&lt;/a&gt; simply states that it &amp;#8220;provides multiple layers of security around your information, from access protected data centers, through network and application level security &amp;hellip; Sensitive information, such as your email, messages and passwords, is always encrypted.&amp;#8221; The methods of encryption, whether they are applied in transit or at rest, and other important details related to the security of the service are left out.&lt;/p&gt;

&lt;p&gt;It&amp;#8217;s hard to blame the product description writers for omitting these crucial details, because most users simply don&amp;#8217;t care as long as they feel reasonably secure. It&amp;#8217;s easy to feel secure with assurances like the ones quoted above, and news articles about implementations of forward secrecy in the works at FB. And then you get things like &lt;a href=&#34;http://thenextweb.com/twitter/2012/12/20/twitter-com-login-flaw-causes-passwords-to-be-sent-in-plain-text-in-some-cases/&#34;&gt;Twitter sending passwords in unencrypted form&lt;/a&gt; or &lt;a href=&#34;https://www.trustwave.com/spiderlabs/advisories/TWSL2011-007.txt&#34;&gt;Apple failing to properly authenticate SSL certificates&lt;/a&gt; or a whole &lt;a href=&#34;http://plaintextoffenders.com/&#34;&gt;Tumblr blog of websites that store and send passwords in plaintext&lt;/a&gt;, oops. There&amp;#8217;s a difference between feeling secure and actually being secure on the web, clearly, but paranoia is tiring and you should probably go check on the 12 Facebook notifications that you got while reading this blog post.&lt;/p&gt;

&lt;p&gt;===========&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Appendix A: A Brief, Non-Representative Survey of Company Policies for Securing Data at Rest&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In the course of researching this blog post, I made a post on a certain social media site asking my friends in tech about how their companies secured non-sensitive data at rest, where non-sensitive data includes user-to-user communications and metadata (but not passwords, SSNs, and financial data). The few answers I got were more sophisticated than, &amp;#8220;In plaintext, on a password-protected database,&amp;#8221; but I suspect there&amp;#8217;s some selection bias here. Anonymized responses below.&lt;/p&gt;

&lt;p&gt;_&lt;strong&gt;_&lt;/strong&gt;_&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I&amp;#8217;ve worked with so many apps, and it&amp;#8217;s almost always a database behind a firewall. I&amp;#8217;ve occasionally built systems where financial data was stored in some more secure way: one, where financial data and transaction processing happened on a separate box with no services and a very minimal API (to limit exposure), and where it was impossible to retrieve the sensitive information via the API.&lt;br data-reactid=&#34;.r[n8ym].[0]{comment10200377727028310_4734438}.[2:0].[5:0:right].[4:1].[5:0:left].[2:1].[2:0].[2:0:2].[3:0].[4:0:1]&#34; /&gt;&lt;br data-reactid=&#34;.r[n8ym].[0]{comment10200377727028310_4734438}.[2:0].[5:0:right].[4:1].[5:0:left].[2:1].[2:0].[2:0:2].[3:0].[4:0:2]&#34; /&gt;The other one actually encrypted data using a key that was secured with the user&amp;#8217;s password. It was re-encrypted using the user&amp;#8217;s session on login, so the cleartext was only available when the user was logged in, during a request from that specific client. In this way, sensitive information was protected from our staff, and from an attacker, except that anyone who was actively using the system would be exposed (to a reasonably sophisticated attacker).&lt;br data-reactid=&#34;.r[n8ym].[0]{comment10200377727028310_4734438}.[2:0].[5:0:right].[4:1].[5:0:left].[2:1].[2:0].[2:0:2].[3:0].[4:0:4]&#34; /&gt;&lt;br data-reactid=&#34;.r[n8ym].[0]{comment10200377727028310_4734438}.[2:0].[5:0:right].[4:1].[5:0:left].[2:1].[2:0].[2:0:2].[3:0].[4:0:5]&#34; /&gt;None of these ideas provide protection from a government, though. Client-side encryption doesn&amp;#8217;t really, either. Just look at what happened to Hushmail. I really want there to be some trustable encryption API in the browser, so that client-side encryption for web apps could be a real thing.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;_&lt;strong&gt;_&lt;/strong&gt;_&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;We actually encrypt (with a separately stored per-user key) all of our user message content. It makes me way way more comfortable debugging problems that come up in production knowing I&amp;#8217;m not going to accidentally read a message that was meant for a friend or co-worker. It&amp;#8217;s pretty low-effort and low-resource-intensity for us to do this so it seems silly not to.&lt;/p&gt;

&lt;p&gt;I guess the tradeoff is that for somebody like Facebook they&amp;#8217;d lose the ability to do queries in aggregate to make advertising or similar decisions based on content.&lt;/p&gt;

&lt;p&gt;&amp;hellip; the keys [for encrypting messages] are stored with symmetric encryption. It defends us against outside attackers getting use out of dumps of our database but in theory with access to the layer that gets the messages and has the keys the encryption doesn&amp;#8217;t matter. The practical limit when we&amp;#8217;ve looked at doing more is one where as long as our site can display your messages then there&amp;#8217;s some set of our infrastructure an attacker could use to read those.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;_&lt;strong&gt;_&lt;/strong&gt;_&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;We use client-side encryption with client-generated keys for user history/bookmarks/passwords, etc. So adding a device to access said data involves JPAKE (key exchange) via our servers (which are treated as an untrusted 3rd party).&lt;/p&gt;

&lt;p&gt;This means syncing is hard, but we associate each record with a record ID and sync them if the hash changes.&lt;/p&gt;

&lt;p&gt;For telemetry, we use anonymized data &amp;#8211; uploads are linked to a UUID that only the client stores locally.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
  </channel>
</rss>